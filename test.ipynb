{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T05:39:44.110824Z",
     "start_time": "2021-02-15T05:39:03.967554Z"
    }
   },
   "source": [
    "## translation by gummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gummy import TranslationGummy\n",
    "from gummy.utils import get_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T05:40:53.849462Z",
     "start_time": "2021-02-15T05:39:46.025938Z"
    }
   },
   "outputs": [],
   "source": [
    "with get_driver() as driver:          \n",
    "    model = TranslationGummy(driver=driver, gateway=\"useless\", translator=\"deepl\")\n",
    "    pdf_path = model.toPDF(url=รง\"https://academic.oup.com/brain/article/142/7/1905/5506062\")\n",
    "    print(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post arxiv articles to slack with translationGummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:26:11.940293Z",
     "start_time": "2021-02-15T07:19:32.702512Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "from gummy.cli import translate_journal\n",
    "\n",
    "\n",
    "def parse(data, tag):\n",
    "    # parse atom file\n",
    "    # e.g. Input :<tag>XYZ </tag> -> Output: XYZ\n",
    "\n",
    "    pattern = \"<\" + tag + \">([\\s\\S]*?)<\\/\" + tag + \">\"\n",
    "    if all:\n",
    "        obj = re.findall(pattern, data)\n",
    "    return obj\n",
    "\n",
    "\n",
    "api_url_slack =\n",
    "\n",
    "def search_and_send(query, start, ids, api_url):\n",
    "    while True:\n",
    "        counter = 0\n",
    "        # url of arXiv API\n",
    "        # If you want to customize, please change here.\n",
    "        # detail is shown here, https://arxiv.org/help/api/user-manual\n",
    "        url = 'http://export.arxiv.org/api/query?search_query=submittedDate:[' + previousdate.strftime(\n",
    "            '%Y%m%d') + '0000+TO+' + basedate.strftime('%Y%m%d') + '0000]+AND+' + query\n",
    "        # Get returned value from arXiv API\n",
    "        data = requests.get(url).text\n",
    "        # Parse the returned value\n",
    "        entries = parse(data, \"entry\")\n",
    "        for entry in entries:\n",
    "            # Parse each entry\n",
    "            url = parse(entry, \"id\")[0]\n",
    "            \n",
    "            #print(url)\n",
    "            \n",
    "            if not(url in ids):\n",
    "                title = parse(entry, \"title\")[0]\n",
    "                # abstract = parse(entry, \"summary\")[0]\n",
    "                date = parse(entry, \"published\")[0]\n",
    "                #post to slack\n",
    "                message = \"\\n\".join([\"=\" * 10, \"No.\" + str(counter + 1), \"Title:  \" + title, \"URL: \" + url, \"Published: \" + date])\n",
    "                requests.post(api_url, json={\"text\": message})\n",
    "                #translation by gummy\n",
    "                savefolder =\n",
    "                translate_journal([str(url), '-pdf',savefolder+title +'.pdf'])\n",
    "                \n",
    "                ids.append(url)\n",
    "                counter = counter + 1\n",
    "                #if counter == 10:\n",
    "                if counter == 2:\n",
    "                    return 0\n",
    "        if counter == 0 and len(entries) < 100:\n",
    "            requests.post(api_url, json={\"text\": \"Currently, there is no available papers\"})\n",
    "            return 0\n",
    "        elif counter == 0 and len(entries) == 100:\n",
    "            # When there is no available paper and full query\n",
    "            start = start + 100\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    basedate = datetime.date.today()\n",
    "    previousdate = basedate + datetime.timedelta(days=-5)\n",
    "    print(\"Publish\")\n",
    "    # Set URL of API\n",
    "    # Please change here\n",
    "    api_url = api_url_slack\n",
    "    # Load log of published data\n",
    "    if os.path.exists(\"published.pkl\"):\n",
    "        ids = pickle.load(open(\"published.pkl\",'rb'))\n",
    "    else:\n",
    "        ids = []\n",
    "    # Query for arXiv API\n",
    "    # Please change here\n",
    "    query = \"((abs:spin-orbit torque)+OR+(abs:spin-torque)\" + \\\n",
    "           \"+OR+(abs:orbital Hall)+ OR + (abs:spintronics)+ OR + (abs:Rashba-Edelstein)\" \\\n",
    "            \"+ OR + (abs:spin Hall)+ OR + (abs:Rashba))\"    \n",
    "    #query = \"(abs:spin-orbit torque)\"\n",
    "    start = 0\n",
    "    # Post greeting to your Slack\n",
    "    requests.post(api_url, json={\"text\": \"Hello!!\"})\n",
    "    # Call function\n",
    "    search_and_send(query, start, ids, api_url)\n",
    "    # Update log of published data\n",
    "    pickle.dump(ids, open(\"published.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T06:40:33.553179Z",
     "start_time": "2021-02-15T06:40:33.548352Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def parse(data, tag):\n",
    "    # parse atom file\n",
    "    # e.g. Input :<tag>XYZ </tag> -> Output: XYZ\n",
    "    pattern = \"<\" + tag + \">([\\s\\S]*?)<\\/\" + tag + \">\"\n",
    "    if all:\n",
    "        obj = re.findall(pattern, data)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:16:16.033578Z",
     "start_time": "2021-02-15T07:15:43.799257Z"
    }
   },
   "outputs": [],
   "source": [
    "#url = 'http://arxiv.org/abs/2102.06279v1'\n",
    "url=\n",
    "from gummy.cli import translate_journal\n",
    "savefolder =\n",
    "title = 'a'\n",
    "translate_journal([str(url), '-pdf',savefolder+title +'.pdf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T08:13:16.319854Z",
     "start_time": "2021-02-15T08:13:15.767392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': False, 'error': 'not_in_channel'}\n"
     ]
    }
   ],
   "source": [
    "#coding: utf-8\n",
    "\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import json\n",
    "import time\n",
    "\n",
    "hist_url = \"https://slack.com/api/conversations.history\"\n",
    "delete_url = \"https://slack.com/api/chat.delete\"\n",
    "\n",
    "token = \n",
    "channel = \n",
    "\n",
    "hist_params = {\n",
    "    'channel' : channel,\n",
    "    'token' : token,\n",
    "    'count' : '1'\n",
    "}\n",
    "\n",
    "req = urllib.request.Request(hist_url)\n",
    "hist_params = urllib.parse.urlencode(hist_params).encode('ascii')\n",
    "req.data = hist_params\n",
    "\n",
    "res = urllib.request.urlopen(req)\n",
    "\n",
    "body = res.read()\n",
    "data = json.loads(body)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T08:14:23.419768Z",
     "start_time": "2021-02-15T08:14:22.852219Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for m in data['messages']:\n",
    "    print(m)\n",
    "    delete_params = {\n",
    "        'channel' : channel,\n",
    "        'token' : token,\n",
    "        'ts' :  m[\"ts\"]\n",
    "    }\n",
    "    req = urllib.request.Request(delete_url)\n",
    "    delete_params = urllib.parse.urlencode(delete_params).encode('ascii')\n",
    "    req.data = delete_params\n",
    "\n",
    "    res = urllib.request.urlopen(req)\n",
    "    body = res.read()\n",
    "\n",
    "    print(body)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T08:32:52.543453Z",
     "start_time": "2021-02-15T08:32:52.475548Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Delete old Slack messages at specific channel.\"\"\"\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "\n",
    "DELETE_URL = \"https://slack.com/api/chat.delete\"\n",
    "HISTORY_URL = \"https://slack.com/api/conversations.history\"\n",
    "#API_TOKEN = \n",
    "\n",
    "\n",
    "#TERM = 60 * 60 * 24 * 7  # 1 week\n",
    "TERM = 60 * 60 * 24   # 1 day \n",
    "\n",
    "def clean_old_message(channel_id):\n",
    "    print('Start cleaning message at channel \"{}\".'.format(channel_id))\n",
    "    current_ts = int(datetime.now().strftime('%s'))\n",
    "    messages = get_message_history(channel_id)\n",
    "    print(messages)\n",
    "    for message in messages:\n",
    "        if current_ts - int(re.sub(r'\\.\\d+$', '', message['ts'])) > TERM:\n",
    "            delete_message(channel_id, message['ts'])\n",
    "            sleep(1)\n",
    "\n",
    "\n",
    "def get_message_history(channel_id, count=800):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded'\n",
    "    }\n",
    "    params = {\n",
    "        'token': API_TOKEN,\n",
    "        'channel': channel_id,\n",
    "        'count': str(count)\n",
    "    }\n",
    "\n",
    "    req_url = '{}?{}'.format(HISTORY_URL, urllib.parse.urlencode(params))\n",
    "    req = urllib.request.Request(req_url, headers=headers)\n",
    "\n",
    "    message_history = []\n",
    "    with urllib.request.urlopen(req) as res:\n",
    "        data = json.loads(res.read().decode(\"utf-8\"))\n",
    "        if 'messages' in data:\n",
    "            message_history = data['messages']\n",
    "\n",
    "    return message_history\n",
    "\n",
    "\n",
    "def delete_message(channel_id, message_ts):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded'\n",
    "    }\n",
    "    params = {\n",
    "        'token': API_TOKEN,\n",
    "        'channel': channel_id,\n",
    "        'ts': message_ts\n",
    "    }\n",
    "\n",
    "    req_url = '{}?{}'.format(DELETE_URL, urllib.parse.urlencode(params))\n",
    "    req = urllib.request.Request(req_url, headers=headers)\n",
    "    with urllib.request.urlopen(req) as res:\n",
    "        data = json.loads(res.read().decode(\"utf-8\"))\n",
    "        if 'ok' not in data or data['ok'] is not True:\n",
    "            print('Failed to delete message. ts: {}'.format(message_ts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T08:46:59.764233Z",
     "start_time": "2021-02-15T08:32:53.096259Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post arxiv articles and delete privious posts on slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T10:17:33.160957Z",
     "start_time": "2021-02-15T10:17:09.093786Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import requests\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "from gummy.cli import translate_journal\n",
    "import passes\n",
    "\n",
    "\n",
    "DELETE_URL = \"https://slack.com/api/chat.delete\"\n",
    "HISTORY_URL = \"https://slack.com/api/conversations.history\"\n",
    "\n",
    "\n",
    "#TERM = 60 * 60 * 24 * 7  # 1 week\n",
    "TERM = 60 * 60 * 24 * 2   # 2 day \n",
    "\n",
    "def clean_old_message(channel_id):\n",
    "    print('Start cleaning message at channel \"{}\".'.format(channel_id))\n",
    "    current_ts = int(datetime.now().strftime('%s'))\n",
    "    messages = get_message_history(channel_id)\n",
    "    print(messages)\n",
    "    for message in messages:\n",
    "        if current_ts - int(re.sub(r'\\.\\d+$', '', message['ts'])) > TERM:\n",
    "            delete_message(channel_id, message['ts'])\n",
    "            sleep(1)\n",
    "\n",
    "\n",
    "def get_message_history(channel_id, count=800):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded'\n",
    "    }\n",
    "    params = {\n",
    "        'token': passes.API_TOKEN, #save in passes.py\n",
    "        'channel': channel_id,\n",
    "        'count': str(count)\n",
    "    }\n",
    "\n",
    "    req_url = '{}?{}'.format(HISTORY_URL, urllib.parse.urlencode(params))\n",
    "    req = urllib.request.Request(req_url, headers=headers)\n",
    "\n",
    "    message_history = []\n",
    "    with urllib.request.urlopen(req) as res:\n",
    "        data = json.loads(res.read().decode(\"utf-8\"))\n",
    "        if 'messages' in data:\n",
    "            message_history = data['messages']\n",
    "\n",
    "    return message_history\n",
    "\n",
    "\n",
    "def delete_message(channel_id, message_ts):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded'\n",
    "    }\n",
    "    params = {\n",
    "        'token': passes.API_TOKEN, #save in passes.py\n",
    "        'channel': channel_id,\n",
    "        'ts': message_ts\n",
    "    }\n",
    "\n",
    "    req_url = '{}?{}'.format(DELETE_URL, urllib.parse.urlencode(params))\n",
    "    req = urllib.request.Request(req_url, headers=headers)\n",
    "    with urllib.request.urlopen(req) as res:\n",
    "        data = json.loads(res.read().decode(\"utf-8\"))\n",
    "        if 'ok' not in data or data['ok'] is not True:\n",
    "            print('Failed to delete message. ts: {}'.format(message_ts))\n",
    "\n",
    "\n",
    "def parse(data, tag):\n",
    "    # parse atom file\n",
    "    # e.g. Input :<tag>XYZ </tag> -> Output: XYZ\n",
    "\n",
    "    pattern = \"<\" + tag + \">([\\s\\S]*?)<\\/\" + tag + \">\"\n",
    "    if all:\n",
    "        obj = re.findall(pattern, data)\n",
    "    return obj\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def search_and_send(query, start, ids, api_url):\n",
    "    while True:\n",
    "        counter = 0\n",
    "        # url of arXiv API\n",
    "        # If you want to customize, please change here.\n",
    "        # detail is shown here, https://arxiv.org/help/api/user-manual\n",
    "        url = 'http://export.arxiv.org/api/query?search_query=submittedDate:[' + previousdate.strftime(\n",
    "            '%Y%m%d') + '0000+TO+' + basedate.strftime('%Y%m%d') + '0000]+AND+' + query\n",
    "        # Get returned value from arXiv API\n",
    "        data = requests.get(url).text\n",
    "        # Parse the returned value\n",
    "        entries = parse(data, \"entry\")\n",
    "        for entry in entries:\n",
    "            # Parse each entry\n",
    "            url = parse(entry, \"id\")[0]\n",
    "            #print(url)\n",
    "            \n",
    "            if not(url in ids):\n",
    "                title = parse(entry, \"title\")[0]\n",
    "                # abstract = parse(entry, \"summary\")[0]\n",
    "                date = parse(entry, \"published\")[0]\n",
    "                #post to slack\n",
    "                message = \"\\n\".join([\"=\" * 10, \"No.\" + str(counter + 1), \"Title:  \" + title, \"URL: \" + url, \"Published: \" + date])\n",
    "                requests.post(api_url, json={\"text\": message})\n",
    "                #translation by gummy\n",
    "                translate_journal([str(url), '-pdf',passes.savefolder+title +'.pdf']) #save in passes.py\n",
    "            \n",
    "                \n",
    "                ids.append(url)\n",
    "                counter = counter + 1\n",
    "                #if counter == 10:\n",
    "                if counter == 10: # 10 articles a day\n",
    "                    return 0\n",
    "        if counter == 0 and len(entries) < 100:\n",
    "            requests.post(api_url, json={\"text\": \"Currently, there is no available papers\"})\n",
    "            return 0\n",
    "        elif counter == 0 and len(entries) == 100:\n",
    "            # When there is no available paper and full query\n",
    "            start = start + 100\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    basedate = datetime.date.today()\n",
    "    previousdate = basedate + datetime.timedelta(days=-5)\n",
    "    print(\"Publish\")\n",
    "    # Set URL of API\n",
    "    # Please change here\n",
    "    api_url = passes.api_url_slack #save in passes.py\n",
    "    # Load log of published data\n",
    "    if os.path.exists(\"published.pkl\"):\n",
    "        ids = pickle.load(open(\"published.pkl\",'rb'))\n",
    "    else:\n",
    "        ids = []\n",
    "    # Query for arXiv API\n",
    "    # Please change here\n",
    "    query = \"((abs:spin-orbit torque)+OR+(abs:spin-torque)\" + \\\n",
    "           \"+OR+(abs:orbital Hall)+ OR + (abs:spintronics)+ OR + (abs:Rashba-Edelstein)\" \\\n",
    "            \"+ OR + (abs:spin Hall)+ OR + (abs:Rashba))\"    \n",
    "    #query = \"(abs:spin-orbit torque)\"\n",
    "    start = 0\n",
    "    # Post greeting to your Slack\n",
    "    requests.post(api_url, json={\"text\": \"Hello!!\"})\n",
    "    # Call function\n",
    "    search_and_send(query, start, ids, api_url)\n",
    "    # Update log of published data\n",
    "    pickle.dump(ids, open(\"published.pkl\", \"wb\"))\n",
    "    \n",
    "    clean_old_message(passes.channelid) #delete privious posts  #save in passes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T10:17:39.178041Z",
     "start_time": "2021-02-15T10:17:39.169022Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T10:17:43.499878Z",
     "start_time": "2021-02-15T10:17:43.482916Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T11:05:07.352961Z",
     "start_time": "2021-02-15T11:04:56.308983Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
